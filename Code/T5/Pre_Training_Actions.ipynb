{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "2h1MRzBLtex2",
        "outputId": "9ca5e0e7-2849-4677-baf3-88cd48719c0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow==2.9\n",
            "  Downloading tensorflow-2.9.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 511.7 MB 205 bytes/s \n",
            "\u001b[?25hCollecting t5\n",
            "  Downloading t5-0.9.3-py3-none-any.whl (153 kB)\n",
            "\u001b[K     |████████████████████████████████| 153 kB 72.2 MB/s \n",
            "\u001b[?25hCollecting tensorflow-text==2.9\n",
            "  Downloading tensorflow_text-2.9.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.6 MB 61.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9) (2.1.1)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9) (0.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9) (1.6.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9) (57.4.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9) (1.3.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9) (1.1.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9) (1.51.1)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9) (2.9.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9) (14.0.6)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9) (3.3.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9) (3.19.6)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9) (0.2.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9) (0.28.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9) (1.21.6)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9) (1.14.1)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9) (1.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9) (4.4.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9) (3.1.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9) (2.9.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9) (1.15.0)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9) (2.9.0)\n",
            "Requirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-text==2.9) (0.12.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow==2.9) (0.38.4)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9) (2.15.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9) (0.4.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9) (3.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9) (5.2.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow==2.9) (5.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow==2.9) (3.11.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9) (2022.12.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9) (3.2.2)\n",
            "Collecting rouge-score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 55.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from t5) (1.3.5)\n",
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n",
            "\u001b[K     |████████████████████████████████| 118 kB 69.8 MB/s \n",
            "\u001b[?25hCollecting mesh-tensorflow[transformer]>=0.1.13\n",
            "  Downloading mesh_tensorflow-0.1.21-py3-none-any.whl (385 kB)\n",
            "\u001b[K     |████████████████████████████████| 385 kB 61.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: editdistance in /usr/local/lib/python3.8/dist-packages (from t5) (0.5.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from t5) (1.13.0+cu116)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.8/dist-packages (from t5) (0.5.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from t5) (1.0.2)\n",
            "Collecting transformers>=2.7.0\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 59.5 MB/s \n",
            "\u001b[?25hCollecting seqio\n",
            "  Downloading seqio-0.0.13-py3-none-any.whl (319 kB)\n",
            "\u001b[K     |████████████████████████████████| 319 kB 70.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (from t5) (3.7)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from t5) (1.7.3)\n",
            "Requirement already satisfied: babel in /usr/local/lib/python3.8/dist-packages (from t5) (2.11.0)\n",
            "Collecting tfds-nightly\n",
            "  Downloading tfds_nightly-4.8.0.dev202212310044-py3-none-any.whl (5.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.2 MB 55.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.8/dist-packages (from mesh-tensorflow[transformer]>=0.1.13->t5) (0.16.0)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.8/dist-packages (from mesh-tensorflow[transformer]>=0.1.13->t5) (4.6.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers>=2.7.0->t5) (6.0)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 68.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers>=2.7.0->t5) (4.64.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 54.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers>=2.7.0->t5) (3.8.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers>=2.7.0->t5) (2022.6.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->tensorflow==2.9) (3.0.9)\n",
            "Requirement already satisfied: pytz>=2015.7 in /usr/local/lib/python3.8/dist-packages (from babel->t5) (2022.6)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk->t5) (1.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk->t5) (7.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->t5) (2.8.2)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.8/dist-packages (from sacrebleu->t5) (0.8.10)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.6.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.8/dist-packages (from sacrebleu->t5) (4.9.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->t5) (3.1.0)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.8/dist-packages (from seqio->t5) (0.3.25+cuda11.cudnn805)\n",
            "Collecting clu\n",
            "  Downloading clu-0.0.8-py3-none-any.whl (96 kB)\n",
            "\u001b[K     |████████████████████████████████| 96 kB 4.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jax in /usr/local/lib/python3.8/dist-packages (from seqio->t5) (0.3.25)\n",
            "Collecting flax\n",
            "  Downloading flax-0.6.3-py3-none-any.whl (197 kB)\n",
            "\u001b[K     |████████████████████████████████| 197 kB 71.0 MB/s \n",
            "\u001b[?25hCollecting ml-collections\n",
            "  Downloading ml_collections-0.1.1.tar.gz (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 6.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: etils[epath] in /usr/local/lib/python3.8/dist-packages (from clu->seqio->t5) (0.9.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.8/dist-packages (from etils[epath]->clu->seqio->t5) (5.10.1)\n",
            "Collecting orbax\n",
            "  Downloading orbax-0.0.23-py3-none-any.whl (66 kB)\n",
            "\u001b[K     |████████████████████████████████| 66 kB 4.9 MB/s \n",
            "\u001b[?25hCollecting rich>=11.1\n",
            "  Downloading rich-13.0.0-py3-none-any.whl (238 kB)\n",
            "\u001b[K     |████████████████████████████████| 238 kB 69.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: msgpack in /usr/local/lib/python3.8/dist-packages (from flax->clu->seqio->t5) (1.0.4)\n",
            "Collecting optax\n",
            "  Downloading optax-0.1.4-py3-none-any.whl (154 kB)\n",
            "\u001b[K     |████████████████████████████████| 154 kB 69.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from flax->clu->seqio->t5) (3.2.2)\n",
            "Collecting tensorstore\n",
            "  Downloading tensorstore-0.1.28-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.3 MB 54.9 MB/s \n",
            "\u001b[?25hCollecting commonmark<0.10.0,>=0.9.0\n",
            "  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[K     |████████████████████████████████| 51 kB 7.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.8/dist-packages (from rich>=11.1->flax->clu->seqio->t5) (2.6.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->flax->clu->seqio->t5) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->flax->clu->seqio->t5) (0.11.0)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.8/dist-packages (from ml-collections->clu->seqio->t5) (0.5.5)\n",
            "Collecting chex>=0.1.5\n",
            "  Downloading chex-0.1.5-py3-none-any.whl (85 kB)\n",
            "\u001b[K     |████████████████████████████████| 85 kB 4.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.8/dist-packages (from chex>=0.1.5->optax->flax->clu->seqio->t5) (0.12.0)\n",
            "Requirement already satisfied: dm-tree>=0.1.5 in /usr/local/lib/python3.8/dist-packages (from chex>=0.1.5->optax->flax->clu->seqio->t5) (0.1.7)\n",
            "Collecting cached_property\n",
            "  Downloading cached_property-1.5.2-py2.py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.8/dist-packages (from orbax->flax->clu->seqio->t5) (3.6.4)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.8/dist-packages (from pytest->orbax->flax->clu->seqio->t5) (1.4.1)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.8/dist-packages (from pytest->orbax->flax->clu->seqio->t5) (1.11.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.8/dist-packages (from pytest->orbax->flax->clu->seqio->t5) (0.7.1)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from pytest->orbax->flax->clu->seqio->t5) (9.0.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.8/dist-packages (from pytest->orbax->flax->clu->seqio->t5) (22.1.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->t5) (0.3.6)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->t5) (2.3)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->t5) (0.10.2)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->t5) (1.12.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-metadata->tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->t5) (1.57.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from tfds-nightly->t5) (5.4.8)\n",
            "Building wheels for collected packages: rouge-score, ml-collections\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24955 sha256=09e9788694ae82468b974b479123a948093075a2a976a6ccdd406f97b4163113\n",
            "  Stored in directory: /root/.cache/pip/wheels/24/55/6f/ebfc4cb176d1c9665da4e306e1705496206d08215c1acd9dde\n",
            "  Building wheel for ml-collections (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ml-collections: filename=ml_collections-0.1.1-py3-none-any.whl size=94524 sha256=dbb7ad7ecb1c95797989a6a6d5979836f34bf03a96936120af450925e396100b\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/9f/a9/9e8309035a5bf09ed9086bbca8c9b74cb6413d3eb203e2bc8c\n",
            "Successfully built rouge-score ml-collections\n"
          ]
        }
      ],
      "source": [
        "from IPython.display import clear_output \n",
        "!pip install tensorflow==2.9 t5 tensorflow-text==2.9\n",
        "#!pip install -q t5 tensorflow-text==2.4.3\n",
        "#!pip install -q tensorflow-text==2.8.0rc0\n",
        "\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KAWZyTi1VOSe"
      },
      "outputs": [],
      "source": [
        "print(\"Installing dependencies...\")\n",
        "import functools\n",
        "import os\n",
        "import gin\n",
        "import tensorflow_gcs_config\n",
        "from google.colab import auth\n",
        "import tensorflow.compat.v1 as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from contextlib import contextmanager\n",
        "import logging as py_logging\n",
        "import t5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XaYwFluwVOqj"
      },
      "outputs": [],
      "source": [
        "TOKENIZER_DIR = \"gs://github-actions-generation/tokenizer\" #@param { type: \"string\" }\n",
        "if not TOKENIZER_DIR or TOKENIZER_DIR == \"gs://\": \n",
        "  raise ValueError(\"You must enter a TOKENIZER_DIR.\")\n",
        "\n",
        "print(\"Setting up GCS access...\")\n",
        "os.environ['USE_AUTH_EPHEM'] = '0'\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "# Set credentials for GCS reading/writing from Colab and TPU.\n",
        "TPU_TOPOLOGY = \"2x2\"\n",
        "try:\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "  TPU_ADDRESS = tpu.get_master()\n",
        "  print('Running on TPU:', TPU_ADDRESS)\n",
        "except ValueError:\n",
        "  raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
        "tf.config.experimental_connect_to_host(TPU_ADDRESS)\n",
        "tensorflow_gcs_config.configure_gcs_from_colab_auth()\n",
        "\n",
        "tf.disable_v2_behavior()\n",
        "\n",
        "\n",
        "#LOGGING\n",
        "tf.get_logger().propagate = False\n",
        "py_logging.root.setLevel('INFO')\n",
        "\n",
        "@contextmanager\n",
        "def tf_verbosity_level(level):\n",
        "  og_level = tf.logging.get_verbosity()\n",
        "  tf.logging.set_verbosity(level)\n",
        "  yield\n",
        "  tf.logging.set_verbosity(og_level)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WyI3CXuOpbX2",
        "outputId": "c1236d08-3350-4e84-8ab6-a4b8ff0803da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "gs://github-actions-generation/tokenizer/sp-actions-bpe.model\n"
          ]
        }
      ],
      "source": [
        "from t5.data import postprocessors as t5_postprocessors\n",
        "from t5.seqio import Feature,SentencePieceVocabulary\n",
        "\n",
        "\n",
        "VOCAB_PREFIX = 'sp-actions-bpe'\n",
        "vocab_model_path = os.path.join(TOKENIZER_DIR, f'{VOCAB_PREFIX}.model')\n",
        "vocab_path = os.path.join(TOKENIZER_DIR, f'{VOCAB_PREFIX}.vocab')\n",
        "print(vocab_model_path)\n",
        "\n",
        "\n",
        "num_special_mask_tokens = 100\n",
        "TaskRegistry = t5.data.TaskRegistry\n",
        "TfdsTask = t5.data.TfdsTask\n",
        "\n",
        "\n",
        "def get_default_vocabulary():\n",
        "  return SentencePieceVocabulary(vocab_model_path, num_special_mask_tokens)\n",
        "\n",
        "DEFAULT_OUTPUT_FEATURES = {\n",
        "    \"inputs\": Feature(\n",
        "        vocabulary=get_default_vocabulary(), add_eos=True, required=False),\n",
        "\n",
        "    \"targets\": Feature(\n",
        "        vocabulary=get_default_vocabulary(), add_eos=True)\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glLJUm1dxIiH",
        "outputId": "a436a6a8-4ccb-4d82-e788-7e7feb24c720"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A few raw train examples...\n",
            "{'input': b\"{'version': 1, 'root<extra_id_0> {'level': '<extra_id_1> ', 'handlers': ['file', '<extra_id_2> ']}, 'loggers<extra_id_3> {'apscheduler': {'level<extra_id_4> 'ERROR', 'handlers': ['file', '<extra_id_5> ']}}, 'handlers': {'<extra_id_6> ': {'class': '<extra_id_7> .StreamHandler', 'level': 'INFO',<extra_id_8> atter': 'console_form<extra_id_9> '}, 'file<extra_id_10> {'class': 'logging.<extra_id_11> .TimedR<extra_id_12> atingFileHandler', '<extra_id_13> ': 'file_formatters', 'filename<extra_id_14> '${workdir}/logs/robot.log', 'level':<extra_id_15> DEBUG', 'when': 'midnight', 'interval': 1}},<extra_id_16> atters': {'<extra_id_17> _formatters':<extra_id_18> format': '%(asctime)s - %(threadName)s -<extra_id_19> (levelname)s: %(message)<extra_id_20> ', 'datefmt': '%Y/%<extra_id_21> d<extra_id_22> H:%<extra_id_23> :%S'}, 'file_formatters': {'format': '%(asctime<extra_id_24> s - %(threadName<extra_id_25> s<extra_id_26> %(levelname)s: %(message)s<extra_id_27> 'datefmt': ' %Y<extra_id_28> m<extra_id_29> d %H:%<extra_id_30> :%<extra_id_31>\", 'output': b\"<extra_id_0> ':<extra_id_1> INFO<extra_id_2> console<extra_id_3> ':<extra_id_4> ':<extra_id_5> console<extra_id_6> console<extra_id_7> logging<extra_id_8> 'form<extra_id_9> atters<extra_id_10> ':<extra_id_11> handlers<extra_id_12> ot<extra_id_13> formatter<extra_id_14> ':<extra_id_15> '<extra_id_16> 'form<extra_id_17> console<extra_id_18> {'<extra_id_19> %<extra_id_20> s<extra_id_21> m/%<extra_id_22> %<extra_id_23> M<extra_id_24> )<extra_id_25> )<extra_id_26> -<extra_id_27> ',<extra_id_28> /%<extra_id_29> /%<extra_id_30> M<extra_id_31> S'}}}<extra_id_32>\"}\n",
            "{'input': b\"{'beno<extra_id_0> f': {'name': 'Florent Benoit', 'title': 'Maint<extra_id_1> of Podman Desktop<extra_id_2> url': 'https://github.com/benoitf',<extra_id_3> image_url': 'https<extra_id_4> github.<extra_id_5> /<extra_id_6> oitf<extra_id_7> png'}, 'deekay<extra_id_8> ': {'<extra_id_9> ': '<extra_id_10> Kumar', 'title': 'Technical PMM Intern', 'url': 'https://github.com/de<extra_id_11> ay23<extra_id_12> '<extra_id_13> url<extra_id_14> 'https://github.com/deekay2310.png'}}\", 'output': b\"<extra_id_0> it<extra_id_1> ainer<extra_id_2> ', '<extra_id_3> '<extra_id_4> ://<extra_id_5> com<extra_id_6> ben<extra_id_7> .<extra_id_8> 2310<extra_id_9> name<extra_id_10> Dev<extra_id_11> ek<extra_id_12> 10',<extra_id_13> image_<extra_id_14> ':<extra_id_15>\"}\n",
            "{'input': b\"{'type': '<extra_id_0> ', 'device': {'name':<extra_id_1> ra<extra_id_2> ',<extra_id_3> vendor': 'google<extra_id_4> ices'}, 'platform':<extra_id_5> product_makefile': 'device/<extra_id_6> /raviole/aosp_<extra_id_7> ven<extra_id_8> mk', 'namespaces':<extra_id_9> hard<extra_id_10> /google/pixel'], 'sepolicy_dirs': ['hardware/google/pixel-<extra_id_11> ', 'device/google/gs101<extra_id_12> policy']}, '<extra_id_13> ': ['snipp<extra_id_14> /2019.yml'],<extra_id_15> generate': {'<extra_id_16> rides': True,<extra_id_17> presigned': True, 'flat_apex': False, 'files': True,<extra_id_18> props': True,<extra_id_19> sepolicy<extra_id_20> dirs': True,<extra_id_21> overlays': True, '<extra_id_22> f': True, 'factory<extra_id_23> firmware': True, 'ota_firmware': True, '<extra_id_24> ': True}, 'filters':<extra_id_25> props': {'mode': 'exclude', 'match': ['ro.gfx.angle.supported'],<extra_id_26> prefix': ['setup<extra_id_27> .'], 'suffix': ['.device'], 'substring':<extra_id_28> boot<extra_id_29> 'regex':<extra_id_30> ^ro\\\\\\\\.surface<extra_id_31> linger\\\\\\\\.(?:<extra_id_32> _ms$', '^.*[0-9].*$']}, 'overlay_keys':<extra_id_33> ['android:<extra_id_34> -<extra_id_35> /config<extra_id_36> companionDevicePackages',<extra_id_37> com<extra_id_38> .wifi.resources/WifiCustom<extra_id_39> :<extra_id_40> /config_wifi_framework_wifi<extra_id_41> score_good_link_speed_5']}, 'overlay_values':<extra_id_42> string': ['com.google.android.<extra_id_43> ms']}, 'over<extra_id_44> _files':<extra_id_45> match': ['HbmSVManager__auto_generated_rro_product.apk']}, 'partitions': {'match': ['<extra_id_46> ', 'modem']}, 'presigned': {'match': ['system_ext<extra_id_47> priv-app/Eu<extra_id_48> cSupportP<extra_id_49> /<extra_id_50> uiccSu<extra_id_51> Pixel.apk']}, 'sepolicy_dirs': {'match': ['hardware/google/pi<extra_id_52> sepolicy/ramdump']}, 'dep_files':<extra_id_53> match':<extra_id_54> vendor/lib/libOpenCL.<extra_id_55> '<extra_id_56> /lib64/libOpenCL.so']}, 'files': {'match<extra_id_57> product/<extra_id_58> /libhwinfo.jar']}}}\", 'output': b\"<extra_id_0> device<extra_id_1> '<extra_id_2> ven<extra_id_3> '<extra_id_4> _dev<extra_id_5> {'<extra_id_6> google<extra_id_7> ra<extra_id_8> .<extra_id_9> ['<extra_id_10> ware<extra_id_11> sepolicy<extra_id_12> -se<extra_id_13> includes<extra_id_14> ets<extra_id_15> '<extra_id_16> over<extra_id_17> '<extra_id_18> '<extra_id_19> '<extra_id_20> _<extra_id_21> '<extra_id_22> vint<extra_id_23> _<extra_id_24> products<extra_id_25> {'<extra_id_26> '<extra_id_27> wizard<extra_id_28> ['.<extra_id_29> .'],<extra_id_30> ['<extra_id_31> _f<extra_id_32> .*)<extra_id_33> {'match':<extra_id_34> string<extra_id_35> array<extra_id_36> _<extra_id_37> '<extra_id_38> .android<extra_id_39> ization<extra_id_40> integer<extra_id_41> _<extra_id_42> {'sub<extra_id_43> g<extra_id_44> lay<extra_id_45> {'<extra_id_46> vendor<extra_id_47> /<extra_id_48> ic<extra_id_49> ixel<extra_id_50> E<extra_id_51> pport<extra_id_52> xel-<extra_id_53> {'<extra_id_54> ['<extra_id_55> so',<extra_id_56> vendor<extra_id_57> ': ['<extra_id_58> framework<extra_id_59>\"}\n",
            "{'input': b\"{'<extra_id_0> ': 'device-list', 'includes': ['pixel<extra_id_1> 9.yml<extra_id_2> 'pixel2020.yml',<extra_id_3> pixel<extra_id_4> 1.yml<extra_id_5> 'devices': ['raven.yml', 'orio<extra_id_6> .yml']}\", 'output': b\"<extra_id_0> type<extra_id_1> 201<extra_id_2> ',<extra_id_3> '<extra_id_4> 202<extra_id_5> '],<extra_id_6> le<extra_id_7>\"}\n",
            "{'input': b\"{'type': '<extra_id_0> -list', 'devices': ['raven.yml', 'oriole.<extra_id_1>\", 'output': b\"<extra_id_0> device<extra_id_1> yml']}<extra_id_2>\"}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<t5.data.dataset_providers.FunctionTask at 0x7fd80525f210>"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "path_pretraining_task1 = 'gs://github-actions-generation/datasets/pretrain.tsv'\n",
        "\n",
        "nq_tsv_path = {\n",
        "    \"train\":      path_pretraining_task1,\n",
        "}\n",
        "\n",
        "\n",
        "def nq_dataset_task1(split, shuffle_files=True):\n",
        "  # We only have one file for each split.\n",
        "  del shuffle_files\n",
        "\n",
        "  # Load lines from the text file as examples.\n",
        "\n",
        "  ds = tf.data.TextLineDataset(nq_tsv_path[split])\n",
        "  ds = ds.map(\n",
        "      functools.partial(tf.io.decode_csv, record_defaults=[\"string\",\"string\"],\n",
        "                        field_delim=\"\\t\", use_quote_delim=False),\n",
        "      num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "  \n",
        "  ds = ds.map(lambda *ex: dict(zip([\"input\", \"output\"], ex)))\n",
        "  return ds\n",
        "\n",
        "print(\"A few raw train examples...\")\n",
        "for ex in tfds.as_numpy(nq_dataset_task1(\"train\").take(5)):\n",
        "    print(ex)\n",
        "\n",
        "\n",
        "def preprocessing_task1(ds):\n",
        "\n",
        "  def to_inputs_and_targets(ex):\n",
        "\n",
        "        inputs = tf.strings.join(['denoising: ' + ex['input']], separator=' ')\n",
        "        class_label = tf.strings.join([ex['output']], separator=' ')\n",
        "        return {'inputs': inputs, 'targets': class_label }\n",
        "    \n",
        "  return ds.map(to_inputs_and_targets, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "    \n",
        "t5.data.TaskRegistry.remove('masking_task_pretraining')\n",
        "t5.data.TaskRegistry.add(\n",
        "        \"masking_task_pretraining\",\n",
        "        dataset_fn = nq_dataset_task1,\n",
        "        splits = [\"train\"],\n",
        "        text_preprocessor = preprocessing_task1,\n",
        "        output_features = DEFAULT_OUTPUT_FEATURES\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDEHaEz9uP5z",
        "outputId": "fdae2b2d-926d-46fb-c5bc-48995a811cb0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<absl.flags._flagvalues.FlagHolder at 0x7fd8052571d0>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def _rate_num_input_examples(task):\n",
        "  if \"train\" in task.splits:\n",
        "    return float(task.num_input_examples(\"train\"))\n",
        "  elif \"validation\" in task.splits:\n",
        "    return float(task.num_input_examples(\"validation\"))\n",
        "  else:\n",
        "    raise ValueError(\"Task %s does not have a train or validation split.\" % (task.name))\n",
        "\n",
        "FLAGS = tf.app.flags.FLAGS\n",
        "tf.app.flags.DEFINE_string ('f', '', 'kernel')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_3Qx699vN302"
      },
      "outputs": [],
      "source": [
        "from mesh_tensorflow.transformer.learning_rate_schedules import learning_rate_schedule_noam\n",
        "from t5 import models\n",
        "\n",
        "MODEL_SIZE = \"small\" \n",
        "\n",
        "MODEL_DIR = 'gs://github-actions-generation/models/pre-trained-models/yaml'\n",
        "model_parallelism, train_batch_size, keep_checkpoint_max = {\n",
        "    \"small\": (1, 128, 50),\n",
        "    \"base\": (2, 16, 8),\n",
        "    \"large\": (8, 64, 4),\n",
        "    \"3B\": (8, 16, 1),\n",
        "    \"11B\": (8, 16, 1)}[MODEL_SIZE]\n",
        "\n",
        "tf.io.gfile.makedirs(MODEL_DIR)\n",
        "\n",
        "model = models.mtf_model.MtfModel(\n",
        "    model_dir=MODEL_DIR,\n",
        "    tpu=TPU_ADDRESS,\n",
        "    tpu_topology=TPU_TOPOLOGY,\n",
        "    model_parallelism=model_parallelism,\n",
        "    batch_size=train_batch_size,\n",
        "    learning_rate_schedule = learning_rate_schedule_noam,\n",
        "    sequence_length={\"inputs\": 512, \"targets\": 512},\n",
        "    save_checkpoints_steps=10000,\n",
        "    keep_checkpoint_max=keep_checkpoint_max,\n",
        "    iterations_per_loop=100,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6oHp5ScE7nf2",
        "outputId": "e0bcb447-f89e-4f4e-d1d6-ae45e1242c7f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/training_util.py:397: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "WARNING:absl:Using an uncached FunctionDataset for training is not recommended since it often results in insufficient shuffling on restarts, resulting in overfitting. It is highly recommended that you cache this task before training with it or use a data source that supports lower-level shuffling (e.g., FileDataSource).\n",
            "SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n",
            "Using default tf glorot_uniform_initializer for variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saver.py:1175: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file utilities to get mtimes.\n",
            "From /usr/local/lib/python3.7/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py:758: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Prefer Variable.assign which has equivalent behavior in 2.X.\n"
          ]
        }
      ],
      "source": [
        "PATH_GIN_FILE = '/content/operative_config.gin'\n",
        "import gin\n",
        "\n",
        "with gin.unlock_config():\n",
        "    gin.parse_config_file(PATH_GIN_FILE)\n",
        "    #RUN FINE-TUNING\n",
        "    TRAIN_STEPS = 300000\n",
        "    model.train(\"masking_task_pretraining\", TRAIN_STEPS)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DwRZv7jgfCfx"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}