{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# GCS Auth"
      ],
      "metadata": {
        "id": "AgtUgPb7rkja"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MACVkFPerjet"
      },
      "outputs": [],
      "source": [
        "print(\"Setting up GCS access...\")\n",
        "import os\n",
        "os.environ['USE_AUTH_EPHEM'] = '0'\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set up"
      ],
      "metadata": {
        "id": "ebguvdxHrwci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gcsfs\n",
        "import tensorflow.compat.v1 as tf"
      ],
      "metadata": {
        "id": "e_LGjEOCrxx_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Helper functions "
      ],
      "metadata": {
        "id": "ymK-XztRryDP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def check_model_accuracy(predictions_path, targets_path):\n",
        "  # Get most recent prediction file by sorting by their step.\n",
        "  prediction_file = tf.io.gfile.glob(f\"{predictions_path}\")[0]\n",
        "  # print(f\"Checking accuracy of: {prediction_file}\")\n",
        "  targets = []\n",
        "  with  tf.io.gfile.GFile(targets_path, \"r\") as f_targets, \\\n",
        "        tf.io.gfile.GFile(prediction_file, \"r\") as f_pred:\n",
        "    # Read targets (real method names) and predictions made by model\n",
        "    targets = f_targets.readlines()\n",
        "    predictions = f_pred.readlines()\n",
        "    \n",
        "    assert len(targets) == len(predictions), f\"{len(targets)} != {len(predictions)}\"\n",
        "\n",
        "    # comapre two sets\n",
        "    perfect_predictions = 0\n",
        "    for x,y in zip(targets, predictions):\n",
        "      x = ''.join(x.split())   # To fix double-space issue\n",
        "      y = ''.join(y.split())\n",
        "      if x == y:\n",
        "        perfect_predictions += 1\n",
        "    accuracy = perfect_predictions*100.0/len(targets)    \n",
        "    # print(f\"Instances: {len(targets)}\\t\\tModel Accuracy: {perfect_predictions*100.0/len(targets):.2f}% (pp={perfect_predictions})\")\n",
        "    # print(f\"=\"*50)\n",
        "    return float(accuracy)"
      ],
      "metadata": {
        "id": "KS7l09rRsKEZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def _is_improvement(monitor_value, reference_value, delta):\n",
        "  '''\n",
        "  Arg 1: monitor_value the accuracy we are checking\n",
        "  Arg 2: reference_value the accuracy we are checking against\n",
        "  arg 3: delta the min difference between the two accuracies to be improved\n",
        "  '''\n",
        "  delta = abs(delta)\n",
        "  return np.greater(monitor_value - delta, reference_value)"
      ],
      "metadata": {
        "id": "DBQsLKANdgjI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_best_checkpoint(checkpoints, accuracies):\n",
        "  baseline = 0\n",
        "  best_acc = 0\n",
        "  best_check = 0\n",
        "  delta = 0.01\n",
        "  patience = 5\n",
        "  wait = 0\n",
        "  for current_check, current_acc in zip(checkpoints, accuracies):\n",
        "    if wait == patience:\n",
        "      print('stopped')\n",
        "      break\n",
        "    wait += 1\n",
        "    if _is_improvement(current_acc, best_acc, delta):\n",
        "      best_acc = current_acc\n",
        "      best_check = current_check\n",
        "      if _is_improvement(current_acc, baseline, delta):\n",
        "        wait = 0\n",
        "    baseline = current_acc\n",
        "  print(best_check, best_acc)"
      ],
      "metadata": {
        "id": "3kiSVpBAsDi4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Variables and paths"
      ],
      "metadata": {
        "id": "O2e9qLD4r14X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The path is fictitious, you may want to adjust it according to your google bucket address\n",
        "target_path = \"gs://github-actions-generation/models/fine-tuned-models/ns/english/abstracted/Best-Performing-Model/test_eval/action_completion_targets\"\n"
      ],
      "metadata": {
        "id": "Fz_8wXeMr8gY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compute accuracies and early stopping"
      ],
      "metadata": {
        "id": "r6Is6idDsAxo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoints = []\n",
        "for i in range(1000000, 1200000, 10000):\n",
        "  checkpoints.append(i)\n"
      ],
      "metadata": {
        "id": "kFkEQNIptxC6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracies = []\n",
        "for checkpoint in checkpoints:\n",
        "  prediction_path = \"gs://github-actions-generation/models/fine-tuned-models/ns/english/abstracted/Best-Performing-Model/test_eval_{}_predictions\".format(checkpoint)\n",
        "  accuracies.append(check_model_accuracy(prediction_path, target_path))"
      ],
      "metadata": {
        "id": "M_ukHFHDsEHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_best_checkpoint(checkpoints, accuracies)"
      ],
      "metadata": {
        "id": "7U_y6ArRsU2c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_acc = max(accuracies[:])\n",
        "index = accuracies.index(max_acc)\n",
        "print(checkpoints[index])"
      ],
      "metadata": {
        "id": "TiAF3kdOufN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "15ntFHc8NSTs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}